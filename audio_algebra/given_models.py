# AUTOGENERATED! DO NOT EDIT! File to edit: ../given-models.ipynb.

# %% ../given-models.ipynb 5
from __future__ import annotations  # for type hints LAION code samples
import os
import pathlib
import numpy as np 
import torch
import torch.nn as nn
import torchaudio
from torchaudio import transforms as T
import pytorch_lightning as pl
import math
from tqdm import trange
import subprocess


# audio-diffusion imports
from copy import deepcopy
import pytorch_lightning as pl
from diffusion.pqmf import CachedPQMF as PQMF
from encoders.encoders import AttnResEncoder1D
from autoencoders.soundstream import SoundStreamXLEncoder
from dvae.residual_memcodes import ResidualMemcodes
from decoders.diffusion_decoder import DiffusionAttnUnet1D
from diffusion.model import ema_update
from einops import rearrange

# rave imports
import rave
import gin

from aeiou.hpc import freeze
from .DiffusionDVAE import DiffusionDVAE, sample

# %% auto 0
__all__ = ['GivenModelClass', 'SpectrogramAE', 'MagSpectrogramAE', 'MagDPhaseSpectrogramAE', 'MelSpectrogramAE', 'DVAEWrapper',
           'RAVEWrapper']

# %% ../given-models.ipynb 8
class GivenModelClass(nn.Module):
    "This provides an (optional) 'shorthand' structure for (some) given_models"
    def __init__(self,
        zero_pad=True,
        make_sizes_match=True,
        ckpt_info={'ckpt_path':'', 'ckpt_url':'','ckpt_hash':'', 'gdrive_path':''}, # info on pretrained checkpoints
        **kwargs,  # these are so that some models can ignore kwargs needed by others
        ):
        super().__init__()
        self.make_sizes_match, self.orig_shape, self.zero_pad, self.ckpt_info  = make_sizes_match, None, zero_pad, ckpt_info
        self.name = self.__class__.__name__  # just a shorthand
        mount_gdrive=True
        self.ckpt_dir = os.path.expanduser('~/checkpoints')
        if not os.path.exists(self.ckpt_dir): os.makedirs(self.ckpt_dir)
    def setup(self, gdrive=True):
        "Setup can include things such as downloading checkpoints"
        pass  
    def encode(self, waveform: torch.Tensor, **kwargs) -> torch.Tensor:
        return None
    def decode(self, waveform: torch.Tensor, **kwargs) -> torch.Tensor:
        return None    
    def forward(self, waveform: torch.Tensor)-> (torch.Tensor, torch.Tensor):
        "Calls .encode() and .decode() in succession, returns both results as tuple"
        reps = self.encode(waveform)
        recons = self.decode(reps)
        return (reps, recons)
    
    def get_checkpoint(self, gdrive=True):
        "This just ensures that the checkpoint file (if one is available) will be present on the local disk at self.ckpt_info['ckpt_path']"
        if self.ckpt_info=={} or all(x=='' for x in self.ckpt_info.values()): 
            print("No checkpoint info available.")
            return
        #@title Mount or Download Checkpoint
        on_colab = os.path.exists('/content')
        if on_colab and gdrive:  # on colab, try to mount checkpoint from drive unless user prefers download
            from google.colab import drive
            drive.mount('/content/drive/') 
            ckpt_file = '/content/drive/'+self.ckpt_info['gdrive_path']
            while not os.path.exists(ckpt_file):
                print(f"\nPROBLEM: Expected to find the checkpoint file at {ckpt_file} but it's not there.\nWhere is it? (Go to the File system in the left sidebar and find it)")
                ckpt_file = input('Enter location of checkpoint file: ')
        else:
            ckpt_file = os.path.expanduser(self.ckpt_info['ckpt_path']) #'checkpoint.ckpt'
            if not os.path.exists(ckpt_file):
                if self.debug: print(f"Can't find checkpoint file {ckpt_file}. Will try to download it..")
                url = self.ckpt_info['ckpt_url']
                # downloading large files from GDrive requires special treatment to bypass the dialog button it wants to throw up
                id = url.split('/')[-2]
                #cmd = f'wget --load-cookies /tmp/cookies.txt "https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate \'https://docs.google.com/uc?export=download&id={id}\' -O- | sed -rn \'s/.*confirm=([0-9A-Za-z_]+).*/\1\\n/p\')&id={id}" -O {ckpt_file} && rm -rf /tmp/cookies.txt'
                cmd = f"gdown -O {ckpt_file} {id}"
                subprocess.run(cmd, shell=True, check=True) 
                #!gdown -O {ckpt_file} {id}

                print(f"\nSecurity: checking hash on downloaded checkpoint file...")
                new_hash = subprocess.run(['shasum', '-a','256',ckpt_file], stdout=subprocess.PIPE).stdout.decode('utf-8').split(' ')[0]
                #new_hash = subprocess.run(['md5sum',ckpt_file], stdout=subprocess.PIPE).stdout.decode('utf-8')
                assert new_hash == self.ckpt_info['ckpt_hash'], "Hashes don't match. STOP THE NOTEBOOK. DO NOT EXECUTE."
                print("Checkpoint hash checks out.")
            else:
                print("Checkpoint found!")
    
    def match_sizes(self, recon) -> torch.Tensor:
        "match recon size to original waveform size, if possible"
        if self.make_sizes_match and (self.orig_shape is not None) and (recon.shape != self.orig_shape):
            if recon.shape[-1] > self.orig_shape[-1]:  # recon is longer
                recon = recon[:,:self.orig_shape[-1]]
            else: # recon is shorter
                recon2 = torch.zeros(self.orig_shape)  # slow but what are you gonna do
                recon2[:,:self.orig_shape[-1]] = recon
                recon = recon2 
            assert recon.shape == self.orig_shape, f"Did not succeed in making size match. recon.shape ({recon.shape}) != self.orig_shape ({self.orig_shape})"
        return recon       
    
    #--- couple extra routines probably only useful for fourier-based AE's but no harm done including them here
    def next_power_of_2(self, x:int) -> int:  
        return 1 if x == 0 else 2**(x - 1).bit_length()

    def zero_pad_po2(self, x:int) -> int:
        "useful for padding to nearest power of 2, useful for fourier-based transforms"
        new_shape = list(x.shape)
        new_shape[-1] = self.next_power_of_2(new_shape[-1])
        new_x = torch.zeros(new_shape).to(x.device)
        new_x[:,:x.shape[-1]] = x
        return new_x

# %% ../given-models.ipynb 10
class SpectrogramAE(GivenModelClass):
    "Raw (complex) spectrogram. See torchaudio.Spectrogram & InverseSpectrogram for kwarg info"
    def __init__(self,
        n_fft=1024,   
        hop_length=256,
        center=True,
        **kwargs,
    ):
        super().__init__()
        self.encoder = T.Spectrogram(power=None, n_fft=n_fft, hop_length=hop_length, center=center, **kwargs)
        self.decoder = T.InverseSpectrogram(    n_fft=n_fft, hop_length=hop_length, center=center, **kwargs)
        
    def encode(self, waveform: torch.Tensor,**kwargs) -> torch.Tensor:
        "Note that this produces complex numbers by default"
        self.orig_shape = waveform.shape # can use this for matching output size later
        return self.encoder(self.zero_pad_po2(waveform)) if self.zero_pad else self.encoder(waveform)

    def decode(self, reps: torch.Tensor, **kwargs) -> torch.Tensor:
        "this decoder offers perfect reconstruction"
        return self.match_sizes( self.decoder(reps) )

# %% ../given-models.ipynb 16
class MagSpectrogramAE(GivenModelClass):
    "Magnitude spectrogram encoder, GriffinLim decoder"
    def __init__(self,
        n_fft=1024,   
        hop_length=256,
        center=True,
        **kwargs,
    ):
        super().__init__()
        self.encoder = T.Spectrogram(power=2, n_fft=n_fft, hop_length=hop_length, center=center, **kwargs)
        self.decoder = T.GriffinLim(          n_fft=n_fft, hop_length=hop_length, **kwargs)
        
    def encode(self, waveform: torch.Tensor, **kwargs) -> torch.Tensor:
        self.orig_shape = waveform.shape
        return self.encoder(self.zero_pad_po2(waveform)) if self.zero_pad else self.encoder(waveform)

    def decode(self, reps: torch.Tensor, **kwargs) -> torch.Tensor:
        "Note that GriffinLim decoding *guesses* at the phase"
        return self.match_sizes( self.decoder(reps) )

# %% ../given-models.ipynb 18
class MagDPhaseSpectrogramAE(GivenModelClass):
    "Magnitude + PhaseChange spectrogram encoder, Exact decoder"
    def __init__(self,
        n_fft=1024,   
        hop_length=256,
        center=True,   # used for fft argument
        init='true',   # initial angle in decoder:'true'|'rand'|'zero'
        use_cos=False, # use vector cosine rule to get angle
        debug=False,
        cheat=False,   # store original signal for comparison later
        **kwargs,
    ):
        super().__init__()
        self.encoder = T.Spectrogram(power=None, n_fft=n_fft, hop_length=hop_length, center=center, **kwargs)
        self.decoder = T.InverseSpectrogram(    n_fft=n_fft, hop_length=hop_length, center=center, **kwargs)
        #self.gl = T.GriffinLim(          n_fft=n_fft, hop_length=hop_length, **kwargs)
        self.use_cos, self.cheat, self.debug, self.init = use_cos, cheat, debug, init
        self.pi = 3.141592653589
        
    def encode(self, waveform: torch.Tensor, **kwargs) -> torch.Tensor:
        self.orig_shape = waveform.shape
        spec =  self.encoder(self.zero_pad_po2(waveform)) if self.zero_pad else self.encoder1(waveform)
        mag, theta = torch.abs(spec), torch.angle(spec)
        if self.debug: theta = torch.where(theta < 0, theta+2*self.pi, theta) # just to make it easier to compare later
        if self.cheat: 
            self.spec_orig, self.mag_orig, self.theta = spec, mag, theta
        if self.use_cos:  # doesn't sound as good imho
            x, y = torch.real(spec), torch.imag(spec)
            mag_tm1 = torch.roll(mag, 1, -1)  # previus timestep rolled forward for subtraction/multiplication
            x_tm1, y_tm1 = torch.roll(x, 1, -1), torch.roll(y, 1, -1)
            numerator, denominator = (x*x_tm1 + y*y_tm1), (mag*mag_tm1)
            acos_arg = torch.where( denominator==0, 1, numerator/denominator) # aviod nans, div by 0
            acos_arg =  torch.clip( acos_arg , -1, 1) # another bounds check
            dtheta = torch.acos(acos_arg)  # could perhaps approximate acos by sqrt(2*(1-cos_arg)) when cos_arg is near 1
        else:  # this is faster and sounds better too. 
            theta_tm1 = torch.roll(theta, 1, -1)
            dtheta = theta-theta_tm1 # this can give bad vals when theta1/2 are on opposite sides of x=0 line
            dtheta = torch.where(dtheta < 0, dtheta+2*self.pi, dtheta)  # force phase to be non-decreasing
        dtheta[:,:,0] = theta[:,:,0]  # encode initial value of theta at first position, helps it sound better
        return torch.concatenate((mag,dtheta))  #package mags together, dthetas together
        
        
    def decode(self, reps: torch.Tensor, **kwargs) -> torch.Tensor:
        "Note that GriffinLim decoding *guesses* at the phase"
        nc = reps.shape[-3] // 2 # number of audio channels
        mag, dtheta = reps[0:nc,:,:], reps[nc:,:,:] # split the packaging
        #return self.gl(mag**2)  # griffin lim cop-out
        if self.cheat:
            theta = self.theta.clone() # cheating
        else:
            theta = torch.zeros(dtheta.shape).to(reps.device)
            if self.init=='true':
                theta[:,:,0] = dtheta[:,:,0]  # initial value of theta, helps it sound better vs. random or zeros
            elif self.init=='rand':
                theta[:,:,0] = torch.rand(dtheta.shape[:-1])
            for t in range(1,reps.shape[-1]):  # integrate theta along the time (last) dimension
                theta[:,:,t] = theta[:,:,t-1] + dtheta[:,:,t]
                theta[:,:,t] = torch.where( theta[:,:,t] < 2*self.pi, theta[:,:,t], theta[:,:,t] - 2*self.pi)            
        spec = mag* ( torch.cos(theta) + 1j*torch.sin(theta) )
        if self.debug:
            self.mag_new, self.theta_new = torch.abs(spec), theta
            self.spec_new = spec
        return self.match_sizes( self.decoder(spec) )

# %% ../given-models.ipynb 21
class MelSpectrogramAE(GivenModelClass):
    "Mel spectrogram encoder, GriffinLim decoder"
    def __init__(self,
        sample_rate=48000,
        n_fft=1024,   
        hop_length=256,
        center=True,
        **kwargs, # these are mainly just so that we can ignore kwargs that other models need
    ):
        super().__init__()
        self.encoder = nn.Sequential( T.MelSpectrogram(sample_rate=sample_rate, n_fft=n_fft, hop_length=hop_length, center=center, **kwargs))
        self.inv_melscale_t = T.InverseMelScale(n_stft=n_fft // 2 + 1)
        self.decoder = T.GriffinLim(n_fft=n_fft, hop_length=hop_length, **kwargs)
        
    def encode(self, waveform: torch.Tensor, **kwargs) -> torch.Tensor:
        self.orig_shape = waveform.shape
        return self.encoder(self.zero_pad_po2(waveform)) if self.zero_pad else self.encoder(waveform)

    def decode(self, melspec: torch.Tensor, **kwargs) -> torch.Tensor:
        spec = self.inv_melscale_t(melspec)
        return self.match_sizes( self.decoder(spec) )
    
    def forward(self, waveform: torch.Tensor)-> (torch.Tensor, torch.Tensor):
        "Calls .encode() and .decode() in succession, returns both results as tuple"
        reps = self.encode(waveform)
        recons = self.decode(reps)
        return (reps, recons)

# %% ../given-models.ipynb 26
class DVAEWrapper(GivenModelClass):
    "Wrapper for (hawley's fork of) Zach's DiffusionDVAE"
    def __init__(self, 
        args_dict = {'num_quantizers':0, 'sample_size': 65536, 'demo_steps':50, 'sample_rate':48000, 'latent_dim': 64, 'pqmf_bands':1, 'ema_decay':0.995, 'num_quantizers':0},
        debug=True,
        **kwargs,
    ):
        super().__init__()
        class DictObj:
            def __init__(self, in_dict:dict):
                for key, val in in_dict.items():
                    if isinstance(val, (list, tuple)):
                        setattr(self, key, [DictObj(x) if isinstance(x, dict) else x for x in val])
                    else:
                        setattr(self, key, DictObj(val) if isinstance(val, dict) else val)
        self.global_args = DictObj(args_dict)
        self.model = DiffusionDVAE(self.global_args)
        self.noise = None 
        self.demo_steps = self.global_args.demo_steps
        self.demo_samples = self.global_args.sample_size 
        self.debug = debug
        self.ckpt_info={'ckpt_url':'https://drive.google.com/file/d/1C3NMdQlmOcArGt1KL7pH32KtXVCOfXKr/view?usp=sharing',
                        'ckpt_hash':'6a304c3e89ea3f7ca023f4c9accc5df8de0504595db41961cc7e8b0d07876ef5',
                        'gdrive_path':'MyDrive/AI/checkpoints/DiffusionDVAE.ckpt',
                        'ckpt_path':'~/checkpoints/dvae_checkpoint.ckpt'}
    
    def encode_it(self, demo_reals):
        module = self.model
        #demo_reals = demo_reals.to(self.device)
        #print("demo_reals.shape = ",demo_reals.shape)

        encoder_input = demo_reals

        if module.pqmf_bands > 1:
            encoder_input = module.pqmf(demo_reals).to(demo_reals.device)

        #encoder_input = encoder_input.to(demo_reals.device)
        noise = torch.randn([demo_reals.shape[0], 2, self.demo_samples]).to(encoder_input.device)

        with torch.no_grad():
            embeddings = module.encoder_ema(encoder_input)
            if module.quantized:
                if debug: print("Hey, did you know you're quantized? ")
                #Rearrange for Memcodes
                embeddings = rearrange(embeddings, 'b d n -> b n d')
                embeddings, _= module.quantizer_ema(embeddings)
                embeddings = rearrange(embeddings, 'b n d -> b d n')
        
        embeddings = torch.tanh(embeddings)
        return embeddings, noise
        
    def encode(self, waveform: torch.Tensor) -> torch.Tensor:
        self.orig_shape = waveform.shape
        self.demo_samples = waveform.shape[-1]
        reps, self.noise = self.model.encode_it(waveform)
        return reps

    def decode(self, reps: torch.Tensor, demo_steps=None) -> torch.Tensor:
        #print("reps.shape, self.noise.shape = ",reps.shape, self.noise.shape)
        if demo_steps is None: demo_steps=self.demo_steps
        fake_batches = sample(self.model.diffusion_ema, self.noise, demo_steps, 0, reps)
        recon = rearrange(fake_batches, 'b d n -> d (b n)') # Put the demos together
        return recon
    
    def setup(self):
        ckpt_file = self.ckpt_info['ckpt_path']
        print(f"DVAE: attempting to load checkpoint {ckpt_file}")
        self.get_checkpoint()
        try:
            self.model = self.model.load_from_checkpoint(ckpt_file, global_args=self.global_args)
        except Exception as e:
            print(f"Sorry, exception = {e}. Going with random weights")
        self.model.encode_it = self.encode_it
        self.model.quantized = self.global_args.num_quantizers > 0 
        self.model.eval() # disable randomness, dropout, etc...
        freeze(self.model)  # freeze the weights for inference

# %% ../given-models.ipynb 32
class RAVEWrapper(GivenModelClass):
    "Wrapper for RAVE"
    def __init__(self,
        pretrained_name='',
        checkpoint_file='percussion.ts',
        config_path='./v2.gin',  # this probably gets ignored
        debug=True,
        **kwargs,
    ):
        self.config_path = config_path
        super().__init__()
        self.debug = debug
        self.ckpt_info={'ckpt_url':'',
                        'ckpt_hash':'',
                        'gdrive_path':'',
                        'ckpt_path':f'{self.ckpt_dir}/{checkpoint_file}'}     
        gin.parse_config_file(self.config_path)
        self.model = rave.RAVE()
        self.model.eval()
   
    def setup(self, gdrive=True):
        "Setup can include things such as downloading checkpoints"
        extension = pathlib.Path(self.ckpt_info['ckpt_path']).suffix
        if self.debug: print("extension =",extension)
        if extension == '.ts':
            self.model = torch.jit.load(self.ckpt_info['ckpt_path'])
        elif extension == '.ckpt':
            self.model.load_state_dict(torch.load(self.ckpt_info['ckpt_path'])["state_dict"])
        else:
            print(f"Sorry, we don't know how to load {extension} checkpoint files. Weights will be uninitialized.")

    def encode(self, waveform: torch.Tensor, **kwargs) -> torch.Tensor:
        with torch.no_grad():
            return self.model.encode(waveform)
    def decode(self, reps: torch.Tensor, **kwargs) -> torch.Tensor:
        with torch.no_grad():
            return self.model.decode(reps) 
    
    def forward(self, waveform: torch.Tensor)-> (torch.Tensor, torch.Tensor):
        "Calls .encode() and .decode() in succession, returns both results as tuple"
        reps = self.encode(waveform)
        recons = self.decode(reps)
        return (reps, recons)
