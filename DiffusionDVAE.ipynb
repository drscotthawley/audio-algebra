{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp DiffusionDVAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DiffusionDVAE\n",
    "\n",
    "> This is a *frozen*, *old* version of one of Zach Evans' diffusion-based autoencoders, for use with audio-algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See Zach Evans' official [audio-diffusion](https://github.com/zqevans/audio-diffusion) for updates. \n",
    "\n",
    "Other parts of `audio-algebra` may use Scott Hawley's \"Python Packaging Fork\" of this: [https://github.com/drscotthawley/audio-diffusion](https://github.com/drscotthawley/audio-diffusion).  That fork is also \"out of date\" w.r.t. @zqevans' research; we'll sync back up someday!  See \"LICENSE(S)\" at the bottom of the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "from copy import deepcopy\n",
    "import math\n",
    "import os, sys\n",
    "import subprocess\n",
    "from collections import namedtuple\n",
    "import numpy as np \n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "from torch import optim, nn, Tensor\n",
    "from torch import multiprocessing as mp\n",
    "from torch.nn import functional as F\n",
    "from torch.utils import data as torchdata\n",
    "import pytorch_lightning as pl\n",
    "#from pytorch_lightning.utilities.distributed import rank_zero_only\n",
    "from tqdm import trange \n",
    "\n",
    "from einops import rearrange\n",
    "from nwt_pytorch import Memcodes\n",
    "\n",
    "# audio-diffusion imports\n",
    "from diffusion.pqmf import CachedPQMF as PQMF # may require some manual labor/ symlinking directories\n",
    "from encoders.encoders import AttnResEncoder1D\n",
    "from autoencoders.soundstream import SoundStreamXLEncoder\n",
    "from dvae.residual_memcodes import ResidualMemcodes\n",
    "from decoders.diffusion_decoder import DiffusionAttnUnet1D\n",
    "from diffusion.model import ema_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_alphas_sigmas(t):\n",
    "    \"\"\"Returns the scaling factors for the clean image (alpha) and for the\n",
    "    noise (sigma), given a timestep.\"\"\"\n",
    "    return torch.cos(t * math.pi / 2), torch.sin(t * math.pi / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_crash_schedule(t):\n",
    "    sigma = torch.sin(t * math.pi / 2) ** 2\n",
    "    alpha = (1 - sigma ** 2) ** 0.5\n",
    "    return alpha_sigma_to_t(alpha, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def alpha_sigma_to_t(alpha, sigma):\n",
    "    \"\"\"Returns a timestep, given the scaling factors for the clean image and for\n",
    "    the noise.\"\"\"\n",
    "    return torch.atan2(sigma, alpha) / math.pi * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@torch.no_grad()\n",
    "def sample(model, x, steps, eta, logits):\n",
    "    \"\"\"Draws samples from a model given starting noise.\"\"\"\n",
    "    ts = x.new_ones([x.shape[0]])\n",
    "\n",
    "    # Create the noise schedule\n",
    "    t = torch.linspace(1, 0, steps + 1)[:-1]\n",
    "\n",
    "    t = get_crash_schedule(t)\n",
    "    \n",
    "    alphas, sigmas = get_alphas_sigmas(t)\n",
    "\n",
    "    # The sampling loop\n",
    "    for i in trange(steps):\n",
    "\n",
    "        # Get the model output (v, the predicted velocity)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            v = model(x, ts * t[i], logits).float()\n",
    "\n",
    "        # Predict the noise and the denoised image\n",
    "        pred = x * alphas[i] - v * sigmas[i]\n",
    "        eps = x * sigmas[i] + v * alphas[i]\n",
    "\n",
    "        # If we are not on the last timestep, compute the noisy image for the\n",
    "        # next timestep.\n",
    "        if i < steps - 1:\n",
    "            # If eta > 0, adjust the scaling factor for the predicted noise\n",
    "            # downward according to the amount of additional noise to add\n",
    "            ddim_sigma = eta * (sigmas[i + 1]**2 / sigmas[i]**2).sqrt() * \\\n",
    "                (1 - alphas[i]**2 / alphas[i + 1]**2).sqrt()\n",
    "            adjusted_sigma = (sigmas[i + 1]**2 - ddim_sigma**2).sqrt()\n",
    "\n",
    "            # Recombine the predicted noise and predicted denoised image in the\n",
    "            # correct proportions for the next step\n",
    "            x = pred * alphas[i + 1] + eps * adjusted_sigma\n",
    "\n",
    "            # Add the correct amount of fresh noise\n",
    "            if eta:\n",
    "                x += torch.randn_like(x) * ddim_sigma\n",
    "\n",
    "    # If we are on the last timestep, output the denoised image\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DiffusionDVAE(pl.LightningModule):\n",
    "    def __init__(self, global_args):\n",
    "        super().__init__()\n",
    "\n",
    "        self.pqmf_bands = global_args.pqmf_bands\n",
    "\n",
    "        if self.pqmf_bands > 1:\n",
    "            self.pqmf = PQMF(2, 70, global_args.pqmf_bands)\n",
    "\n",
    "        capacity = 32\n",
    "\n",
    "        c_mults = [2, 4, 8, 16, 32]\n",
    "        \n",
    "        strides = [4, 4, 2, 2, 2]\n",
    "\n",
    "        self.encoder = SoundStreamXLEncoder(\n",
    "            in_channels=2*global_args.pqmf_bands, \n",
    "            capacity=capacity, \n",
    "            latent_dim=global_args.latent_dim,\n",
    "            c_mults = c_mults,\n",
    "            strides = strides\n",
    "        )\n",
    "        self.encoder_ema = deepcopy(self.encoder)\n",
    "\n",
    "        self.diffusion = DiffusionAttnUnet1D(\n",
    "            io_channels=2, \n",
    "            cond_dim = global_args.latent_dim, \n",
    "            pqmf_bands = global_args.pqmf_bands, \n",
    "            n_attn_layers=4, \n",
    "            c_mults=[256, 256]+[512]*12\n",
    "        )\n",
    "\n",
    "        self.diffusion_ema = deepcopy(self.diffusion)\n",
    "        self.rng = torch.quasirandom.SobolEngine(1, scramble=True)\n",
    "        self.ema_decay = global_args.ema_decay\n",
    "        \n",
    "        self.num_quantizers = global_args.num_quantizers\n",
    "        if self.num_quantizers > 0:\n",
    "            quantizer_class = ResidualMemcodes if global_args.num_quantizers > 1 else Memcodes\n",
    "            \n",
    "            quantizer_kwargs = {}\n",
    "            if global_args.num_quantizers > 1:\n",
    "                quantizer_kwargs[\"num_quantizers\"] = global_args.num_quantizers\n",
    "\n",
    "            self.quantizer = quantizer_class(\n",
    "                dim=global_args.latent_dim,\n",
    "                heads=global_args.num_heads,\n",
    "                num_codes=global_args.codebook_size,\n",
    "                temperature=1.,\n",
    "                **quantizer_kwargs\n",
    "            )\n",
    "\n",
    "            self.quantizer_ema = deepcopy(self.quantizer)\n",
    "\n",
    "    def encode(self, *args, **kwargs):\n",
    "        if self.training:\n",
    "            return self.encoder(*args, **kwargs)\n",
    "        return self.encoder_ema(*args, **kwargs)\n",
    "\n",
    "    def decode(self, *args, **kwargs):\n",
    "        if self.training:\n",
    "            return self.diffusion(*args, **kwargs)\n",
    "        return self.diffusion_ema(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_dict = {'num_quantizers':0, 'sample_size': 65536, 'sample_rate':48000, 'latent_dim': 64, 'pqmf_bands':1, 'ema_decay':0.995, 'num_quantizers':0}\n",
    "global_args = namedtuple(\"global_args\", args_dict.keys())(*args_dict.values())\n",
    "model = DiffusionDVAE(global_args=global_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LICENSE(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|export\n",
    "'''\n",
    "Besides the main LICENSE for this library overall, this particular file uses code by \n",
    "Zach Evans, who used some of Phil Wang's codes.  The licenses for those are as follows:\n",
    "\n",
    "MIT License\n",
    "\n",
    "Copyright (c) 2022 Zach Evans\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "SOFTWARE.\n",
    "\n",
    "\n",
    "MIT License\n",
    "\n",
    "Copyright (c) 2022 Phil Wang\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "SOFTWARE.\n",
    "'''\n",
    "''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
